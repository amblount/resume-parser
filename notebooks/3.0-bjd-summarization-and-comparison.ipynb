{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Summarization and comparison of résumés + job postings\n",
    "\n",
    "\n",
    "### CoNVO\n",
    "\n",
    "**Context:** Bloc is a career services management platform that builds smart career and data management tools for job-seekers and the organizations serving them. In particular, Bloc seeks to provide and facilitate access to tools for effectively presenting job-seekers' credentials and matching employers' job postings, and thereby improve outcomes.\n",
    "\n",
    "**Need:** Career advisors are expected to provide personalized recommendations and assistance to many job-seekers at any given time. To accomplish that, they need to stay up-to-date on the current status of particular job markets, and understand how their group of advisees fit into that space.\n",
    "\n",
    "**Vision:** Automated summarization of the contents of a group of job-seekers' résumés and, separately, open job postings in a particular field(s), along with a quantitative and/or visual representation of the similarity between a set of résumés and job postings, with easy-to-understand outputs for non-technical viewers.\n",
    "\n",
    "**Outcome:** A standalone, proof-of-concept process for summarizing small- to medium-sized collections of text. A separate POC for comparing sets of résumés to sets of job postings in a quantitative and/or visual manner.\n",
    "\n",
    "\n",
    "### Data Summary\n",
    "\n",
    "A collection of ~125 (+ ~2400) résumés as text extracted from PDFs (see Task 1) as well as ~4800 job postings as JSON fetched from external APIs(see Task 2).\n",
    "\n",
    "\n",
    "### Proposed Methodology\n",
    "\n",
    "Unsupervised summarization of many texts is a common and well-studied problem; there's no need for us to reinvent the wheel. Topic modeling (e.g. LDA) is a good bet if you have enough texts and don't require fine detail. Ranking the most important words/terms by frequency or a more sophisticated metric (e.g. tf-idf, bm25) works well for smaller corpora, but doesn't necessarily reveal relationships between concepts. Graph-based methods for extract summarization of key words/terms/sentences (e.g. TextRank) could also work here.\n",
    "\n",
    "Comparing two collections of texts is potentially trickier. An explicit comparison could be made by identifying words/terms that are most important in one corpus and least important in the other (and vice-versa), while an implicit comparison could just show the top words/terms for each corpus side-by-side. Comparing topic models is generally _not_ a valid method. Visualizing the comparison is probably the most important aspect of this task; we want to make it intuitive and interpretable.\n",
    "\n",
    "\n",
    "### Definitions of Success\n",
    "\n",
    "This entire task is icing on the cake. Any concrete outputs will be considered a success!\n",
    "\n",
    "\n",
    "### Risks\n",
    "\n",
    "We may not have enough texts for some unsupervised methods (namely, topic modeling and any deep learning methods)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
